Aqui estÃ¡ a trilha completa formatada em **Markdown**, pronta para ser copiada e colada no arquivo `README.md` do seu repositÃ³rio no GitHub.

---

# ğŸ›¡ï¸ Trilha de Estudos: SeguranÃ§a em IA & LLMs (EdiÃ§Ã£o 2025/2026)

Este repositÃ³rio contÃ©m uma trilha de estudos estruturada para profissionais de seguranÃ§a que desejam se especializar em IA Generativa, cobrindo desde fundamentos atÃ© arquiteturas avanÃ§adas de agentes, o protocolo MCP e as ameaÃ§as mais recentes do cenÃ¡rio "Agentic Security".

---

## ğŸ“˜ MÃ³dulo 1: Fundamentos de AI & LLMs (O Motor)
*Objetivo: Entender como os modelos funcionam, desde os pesos atÃ© a operaÃ§Ã£o ofensiva autÃ´noma.*

- **Conceitos:** Transformers, Foundation Models (ProprietÃ¡rios vs. Open-Weights), e a transiÃ§Ã£o para a **Ofensiva Agentica**.
- **Recursos:**
    - [ğŸ“º] [Intro to LLMs (Andrej Karpathy)](https://www.youtube.com/watch?v=zjkBMFhNj_g)
    - [ğŸ“º] [Visual intro to Transformers (3Blue1Brown)](https://www.youtube.com/watch?v=wjZofJX0v4M)
    - [ğŸ“–] [OpenAI Models Documentation](https://platform.openai.com/docs/models)
    - [ğŸ“–] [Anthropic Models Overview](https://docs.anthropic.com/en/docs/models-overview)
    - [ğŸ“Š] [State of AI Report](https://www.stateof.ai/)
    - [ğŸ“°] [The tools for autonomous offensive operations are shipping (Agentic Security)](https://agenticsecurity.substack.com/p/the-agentic-security-newsletter-week-77e)

---

## ğŸ“˜ MÃ³dulo 2: Arquiteturas de AplicaÃ§Ã£o (RAG, Fine-tuning, Agents & MCP)
*Objetivo: Entender como os dados de negÃ³cio sÃ£o expostos e como agentes interagem com o mundo real via MCP.*

- **Conceitos:** RAG, LoRA, OrquestraÃ§Ã£o com LangGraph, Protocolo MCP e **AI BOM** (AI Bill of Materials).
- **Recursos:**
    - [ğŸ“] [Finetuning LLMs (DeepLearning.ai)](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
    - [ğŸ“º] [LoRA Explained](https://www.youtube.com/watch?v=PXWYUTMt-AU)
    - [ğŸ“] [Advanced RAG (DeepLearning.ai)](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/)
    - [ğŸ“„] [Model Context Protocol (MCP) Official Guide](https://modelcontextprotocol.io/)
    - [ğŸ“] [AI Agents in LangGraph (DeepLearning.ai)](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)
    - [ğŸ“°] [AI BOM Concept & Visibility (Agentic Security)](https://agenticsecurity.substack.com/p/the-agentic-security-newsletter-week-77e)

---

## ğŸ”´ MÃ³dulo 3: SeguranÃ§a Ofensiva (InjeÃ§Ã£o, Jailbreaks e Ataques de Camada Profunda)
*Objetivo: DomÃ­nio completo dos vetores de ataque, desde o prompt simples atÃ© a escalada de privilÃ©gios em agentes.*

- **Conceitos:** Direct/Indirect Prompt Injection, Jailbreaks (DAN), **Excessive Agency**, **Confused Deputy no MCP**, Data Poisoning e Model Extraction.
- **Recursos:**
    - [ğŸŒ] [Simon Willison: Prompt Injection Series](https://simonwillison.net/series/prompt-injection/)
    - [ğŸ“º] [Advanced Prompt Injection (Johann Rehberger)](https://www.youtube.com/watch?v=OhxAdrfHVs8)
    - [ğŸ’»] [Jailbreak Chat (Database de prompts)](https://www.jailbreakchat.com/)
    - [ğŸ“„] [Excessive Agency: The safety risks of autonomous AI agents](https://arxiv.org/abs/2401.05566)
    - [ğŸ› ï¸] [LLM-Attacks (GitHub)](https://github.com/llm-attacks/llm-attacks)
    - [ğŸ“°] [EchoLeak & OpenClaw: Data exfiltration via Agents (Agentic Security)](https://agenticsecurity.substack.com/p/the-agentic-security-newsletter-week-77e)

---

## ğŸ›¡ï¸ MÃ³dulo 4: MitigaÃ§Ã£o, CorreÃ§Ã£o e Hardening (Defesa PrÃ¡tica)
*Objetivo: Implementar "escudos" semÃ¢nticos, gerir identidades nÃ£o-humanas e proteger servidores MCP.*

- **Conceitos:** ValidaÃ§Ã£o de Input/Output, detecÃ§Ã£o de PII, **NHI (Non-Human Identity)** e Agent Behavior Analytics.
- **Recursos:**
    - [ğŸ› ï¸] [LLM-Guard (Scanner de Payloads)](https://github.com/protectai/llm-guard)
    - [ğŸ› ï¸] [Microsoft Presidio (PII Protection)](https://github.com/microsoft/presidio)
    - [ğŸ› ï¸] [NVIDIA NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)
    - [ğŸ“] [Red Teaming LLM Applications (DeepLearning.ai)](https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/)
    - [ğŸ“°] [Agent Behavior Analytics & SOC (Agentic Security)](https://agenticsecurity.substack.com/p/the-agentic-security-newsletter-week-77e)

---

## âš–ï¸ MÃ³dulo 5: Frameworks de GovernanÃ§a e Supply Chain
*Objetivo: Usar os padrÃµes globais para auditar sistemas de IA e gerir riscos de terceiros.*

- **Conceitos:** OWASP Top 10 for LLMs 2025, **OWASP Top 10 for Agentic Applications**, MITRE ATLAS e Supply Chain Security.
- **Recursos:**
    - [ğŸ“‘] [OWASP Top 10 for LLM Applications v2.0](https://genai.owasp.org/)
    - [ğŸ“‘] [OWASP Top 10 for Agentic Applications (Analysis)](https://agenticsecurity.substack.com/p/owasp-top-10-for-agentic-applications)
    - [ğŸ“‘] [MITRE ATLAS Matrix](https://atlas.mitre.org/)
    - [ğŸ“–] [HuggingFace Security Guide](https://huggingface.co/docs/hub/security)
    - [ğŸ—ï¸] [SLSA (Supply-chain Levels for Software Artifacts)](https://slsa.dev/)

---

## ğŸ¢ MÃ³dulo 6: Estudos de Fabricantes e LaboratÃ³rios PrÃ¡ticos (Hands-on)
*Objetivo: Aplicar o conhecimento em ambientes de simulaÃ§Ã£o e estudar implementaÃ§Ãµes reais.*

- **Estudos de Caso (Whitepapers):**
    - [Google] [SAIF (Secure AI Framework)](https://safety.google/cybersecurity-advancements/saif/)
    - [Microsoft] [AI Red Teaming Guide](https://www.microsoft.com/en-us/security/blog/ai-red-team/)
    - [Anthropic] [Responsible Scaling Policy](https://www.anthropic.com/news/anthropic-responsible-scaling-policy)
    - [Sophos/Cisco] [Agentic SOC Frameworks](https://agenticsecurity.substack.com/p/the-agentic-security-newsletter-week-77e)

- **LaboratÃ³rios PrÃ¡ticos:**
    - [ğŸ®] [Gandalf (Lakera)](https://gandalf.lakera.ai/) - Desafio de InjeÃ§Ã£o de Prompt.
    - [ğŸ› ï¸] [Garak](https://github.com/leondz/garak) - Scanner de vulnerabilidades (O "Nmap" dos LLMs).
    - [ğŸ› ï¸] [PyRIT (Microsoft)](https://github.com/Azure/PyRIT) - AutomaÃ§Ã£o de Red Teaming para IA.
    - [ğŸ—ï¸] [RedAiRange](https://github.com/ErdemOzgen/RedAiRange) - LaboratÃ³rio completo para prÃ¡tica de ataques.
    - [ğŸ—ï¸] [AgentDojo](https://github.com/approximatelabs/agentdojo) - SeguranÃ§a para Agentes AutÃ´nomos.

---

## ğŸ”” AtualizaÃ§Ã£o ContÃ­nua
IA Ã© uma Ã¡rea que muda semanalmente. Para se manter atualizado com novos exploits e defesas, acompanhe a newsletter:
- [Agentic Security Substack](https://agenticsecurity.substack.com/)
